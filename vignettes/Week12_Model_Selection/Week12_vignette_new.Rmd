---
title: "Week 12: Model Selection"
author: "Caren Goldberg"
date: "`r Sys.Date()`"
show_toc: true
output:
  knitr:::html_vignette:
    toc: yes
    fig_width: 4 
    fig_height: 3.5
vignette: >
  %\VignetteIndexEntry{Week 12: Model Selection}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
## 1. Overview of Worked Example

### a) Goals and Background

**Goals**: The goal of this worked example is for you to become familiar with creating and analyzing landscape genetic hypotheses using maximum likelihood population effects (MLPE; Van Strien et al. 2012) and information theory. WIth this approach, we focus on evaluating evidence for the influence of landscape on link-based metrics (i.e. genetic distance). Incorporating node-based effects (i.e. pond size, etc.) will be covered in the gravity modeling lab. 

We will re-analyze a dataset from Goldberg and Waits 2010 using a maximum likelihood population effect model (MLPE). 

### b) Data set

In previous labs, you have created genetic distance matrices, so here we are going to start with those data already complete, as are the landscape data. For MLPE, two vectors representing the nodes at the ends of each link must be created. These are already included in the data set (`pop1` and `pop2`). 

Each row in the file 'CSF_network.csv' represents a link between two pairs of sampling locations. The columns contain the following variables:

- **Id**: Link ID.
- **Name**: Link name (combines the two site names).
- **logDc.km**: Genetic distance per geographic distance, log transformed (response variable).
- **LENGTH**: Euclidean distance.
- **slope**: Average slope along the link.
- **solarinso**: Average solar insolation along the link.
- **soils**: Dominant soil type along the link (categorical).
- **ag**: Proportion of agriculture along the link.
- **grass**: Proportion of grassland along the link.
- **shrub**: Proportion of shrubland along the link.
- **hi**: Proportion of high density forest along the link. 
- **lo**: Proportion of low density forest along the link.
- **dev**: Proportion of development (buildings) along the link.
- **forest**: Proportion of forest (the sum of hi and lo) along the link.
- **pop1**: 'From' population.
- **pop2**: 'To' population.

### c) Required R libraries

All required packages should have been installed already when you installed 'LandGenCourse'.

```{r packages global_options, include=TRUE, results="hide", message=FALSE, warning=FALSE}
library(LandGenCourse)
#require(lme4)
#require(usdm)
```

### d) Import data

First, read in the dataset. It is named CSF (Columbia spotted frog) to differentiate it from the RALU dataset you have used in previous labs (same species, very different landscapes). 

```{r}
CSFdata <- read.csv(system.file("extdata", "CSF_network.csv", 
                                        package = "LandGenCourse"))
View(CSFdata) 
```

Take a look at the column names and make sure you and R agree on what everything is called, and on the data types (e.g., factor vs. character).

```{r}
str(CSFdata)
```

- `Name` and `soils` are interpreted as factors,
- `Id`, `pop1` and `pop2` are vectors of integers, and
- everything else is a numeric vector, i.e., continuous variable. 

The response Y in our MLPE models will be `logDc.km`, the genetic distance per geographic distance, log transformed to meet normality assumptions. 

For this exercise, you will test 5 alternative hypotheses. At the end, you will be invited to create your own hypotheses from these variables and test support for them.

## 2. Fitting candidate models

### a) Alternative hypotheses

In information theory, we evaluate evidence for a candidate set of hypotheses that we develop from the literature and theory. Although it is mathematically possible (and often practiced) to fit all possible combinations of input variables, that approach is not consistant with the methodology (see Burnham and Anderson 2002 Chapter 8, the reading for this unit, for more detail). Here, your "a priori"" set of hypotheses (as in the Week 12 Conceptual Exercise) is as follows:

1.	**Full model**: solarinso, forest, ag, shrub, dev
2.	**Landcover model**: ag, shrub, forest, and dev
3.	**Human footprint model**: ag, dev
4.	**Energy conservation model**: slope, shrub, dev
5.	**Historical model**: soils, slope, solarinso

### b) Prepare for model fitting
Because link data are not independant (i.e. the genetic diversity at node 1 influences both the node1/node2 genetic distance and that from node1/node3, etc.), we need to develop a set of random effects to account for this dependancy, so that we seperate the pattern due to this covariance from the signal of landscape influence on genetic distance. We start by creating matrices from the pop1 and pop2 variables:

Create the Zl and ZZ matrices:

```{r}
Zl <- lapply(c("pop1","pop2"), function(nm) Matrix:::fac2sparse(CSFdata[[nm]],
                               "d", drop=FALSE))
ZZ <- Reduce("+", Zl[-1], Zl[[1]])
```

Now we can fit an lmer model to the data. 

```{r}
mod1 <- lme4::lFormula(logDc.km ~ solarinso + forest + ag + shrub + dev + (1|pop1), 
                 data = CSFdata, REML = TRUE)
```

At this point an error message appears: "Warning message: Some predictor variables are on very different scales: consider rescaling". 

Which variable is causing this problem? To check, get R to show you the first few rows of the dataset:

```{r}
head(CSFdata)
```

One of these variables is a lot larger than the others, but has a small range. This often happens with variables such as easting and can cause issues for model fit. The common solution is to z-transform (standardize) the data, which is conveniently done in R using the `scale` function:

```{r}
solarinsoz <- scale(CSFdata$solarinso)
```

We then can attach these data back to our dataframe and check to make sure this worked:

```{r}
CSFdata <- cbind(CSFdata, solarinsoz)
names(CSFdata)
```

If `solarinsoz` is there, you are good.

While we are at it, we will make sure that these variables do not have issues with multicollinearity.

Make a dataframe of just the variables to test (note, you cannot use factors here):

```{r}
CSF.df <- with(CSFdata, data.frame(solarinsoz, forest, dev, shrub, ag))
usdm::vif(CSF.df)
```

If you get an error that there is no package called 'usdm', use install.packages("usdm")

Numbers less than 10, or 3, or 4, depending on who you ask, are considered to not be collinear enough to affect model outcomes. So we are good to go here. What would happen if we added grass to this?

```{r}
usdm::vif(cbind(CSF.df, grass=CSFdata$grass))
```

### c) Fit all five models

Now we have to remake the modeling objects with our new and improved data frame, but referring to our z-transformed data (thanks to Martin Van Strien and Helene Wagner for the base model code):

```{r}
Zl <- lapply(c("pop1","pop2"), function(nm) Matrix:::fac2sparse(CSFdata[[nm]],
                               "d", drop=FALSE))
ZZ <- Reduce("+", Zl[-1], Zl[[1]])
```

Fit an lmer model to the data:

```{r}
mod_1 <- lme4::lFormula(logDc.km ~ solarinsoz + forest + ag + shrub + dev + (1|pop1), 
                 data = CSFdata, REML = TRUE)
```

In the fitted model replace Zt slot:

```{r}
mod_1$reTrms$Zt <- ZZ
```

Refit the model:

```{r}
dfun <- do.call(lme4::mkLmerDevfun, mod_1)
opt <- lme4::optimizeLmer(dfun)
mod1 <- lme4::mkMerMod(environment(dfun), opt, mod_1$reTrms,fr = mod_1$fr)
summary(mod1)
```

This is the fullest model in our dataset (although our models are not completely nested), so we will take a look at the residuals:

```{r}
plot(mod1) 
```

Residuals are centered around zero and do not show large groupings or patterns, although there is some increase in variation at larger numbers (so the model is having a more difficult time predicting larger genetic distances per km). 

There are many more checks that can be done at this point (referenced in the lecture), but for now we are going to leave evaluating model fit at this and fit the other models.

Now we will make a function (called MPLE) to fit the rest of our models, so that we are not typing the same code over and over (which causes errors and long code that is difficult to navigate):


```{r}
MLPE <- function(variables, data) {mod2 <- lme4::lFormula(variables, data = data, REML = TRUE)
dfun <- do.call(lme4::mkLmerDevfun, mod2)
opt <- lme4::optimizeLmer(dfun)
mod_2 <- lme4::mkMerMod(environment(dfun), opt, mod2$reTrms,fr = mod2$fr)
mod2$reTrms$Zt <- ZZ

# Refit the model
dfun <- do.call(lme4::mkLmerDevfun, mod2)
opt <- lme4::optimizeLmer(dfun)
modelout <- lme4::mkMerMod(environment(dfun), opt, mod2$reTrms,fr = mod2$fr)
return(modelout)
}
```

To use this function, we define variables (the model as we want it to run) and data (the object that contains our data)

```{r}
mod2 <- MLPE(logDc.km ~ forest + ag + shrub + dev + (1|pop1), CSFdata)
mod3 <- MLPE(logDc.km ~ ag + dev + (1|pop1), CSFdata)
mod4 <- MLPE(logDc.km ~ slope + shrub + dev + (1|pop1), CSFdata)
mod5 <- MLPE(logDc.km ~ soils + slope + solarinsoz + (1|pop1), CSFdata)
```

### d) Compare evidence for models
Note: package MuMIn will do this for you, but for this exercise it is useful to see all the pieces of what goes into your evaluation. 

In information theory, we use information criteria (AIC, BIC) to evaluate the relative distance of our hypothesis from truth. For more information, see Burnham and Anderson (2002).
```{r}
CSF.IC <- cbind(Model = c(1:5), 
                AIC = c(AIC(mod1), AIC(mod2), AIC(mod3), 
                        AIC(mod4), AIC(mod5)), 
                BIC = c(BIC(mod1), BIC(mod2), BIC(mod3), 
                        BIC(mod4), BIC(mod5)))
CSF.IC
```

We now have some results, great!

Now we will work with these a bit. First, because we do not have an infinite number of samples, we will convert AIC to AICc.

First, find the k parameters used in the model and add them to the table.

```{r}
CSF.IC <- cbind(CSF.IC, 
                k = c(attr(logLik(mod1), "df"), attr(logLik(mod2), "df"), 
                      attr(logLik(mod3), "df"), attr(logLik(mod4), "df"), 
                      attr(logLik(mod5), "df")))
CSF.IC
```

Now, calculate AICc and add it to the dataframe:

```{r}
CSF.IC<- as.data.frame(CSF.IC)
AICc <- CSF.IC$AIC + 2*CSF.IC$k*(CSF.IC$k+1)/(48-CSF.IC$k-1)
CSF.IC <- cbind(CSF.IC, AICc = AICc)
CSF.IC
```

### e) Calculate evidence weights

Next we calculate evidence weights for each model based on AICc and BIC. These can be interpreted as the probability that the model is the closest to truth in the candidate model set. 

Calculate model weights for AICc:

```{r}
AICcmin <- min(CSF.IC$AICc)
RL <- exp(-0.5*(CSF.IC$AICc - AICcmin))
sumRL <- sum(RL)
AICew <- RL/sumRL
CSF.IC <- cbind(CSF.IC, AICew)
```

Calculate model weights for BIC:

```{r}
BICmin <- min(CSF.IC$BIC)
RL.B <- exp(-0.5*(CSF.IC$BIC - BICmin))
sumRL.B <- sum(RL.B)
BICew <- RL.B/sumRL.B
CSF.IC <- cbind(CSF.IC, BICew)
round(CSF.IC,3)
```

In the multi-model inference approach, we can look across all the models in the dataset and their evidence weights to better understand the system. Here we see that models 1 and 5 have very little evidence of being close to the truth, that model 4 has just a little more, and that models 2 and 3 can be seen as competing for which one is closest to truth, at least if you're looking at AIC. BIC imposes a larger penalty for additional parameters, so it has a larger distinction between these. Let's review what these models are:

1.	**Full model**: solarinso, forest, ag, shrub, dev
2.	**Landcover model**: ag, shrub, forest, and dev
3.	**Human footprint model**: ag, dev
4.	**Energy conservation model**: slope, shrub, dev
5.	**Historical model**: soils, slope, solarinso

According to Row et al. (2017), we can use the confidence interval from the variables in the models to identify those that are contributing to landscape resistance. Looking at models 2 and 3, we have some evidence that shrub and forest cover matter, but it's not as strong as the evidence for ag and development. Let's look at the parameter estimates to understand more.

```{r}
summary(mod2)
```

Now we'll estimate the 95% confidence interval for these estimates:

```{r}
confint(mod2, level = 0.95, method = "Wald")
```

The estimates that overlap 0 do not have as much evidence of being important to gene flow, based on simulations in Row et al. (2017). So in this case, there is only strong evidence that agriculture influences the rate of gene flow. Note that because the metric is genetic distance, negative values indicate more gene flow.


**Questions**:

1.	Why would adding in the last land cover cause a high amount of collinearity? Consider how these data were calculated.
2.	What did using AICc (rather than AIC) do to inference from these results?
3.	How does k relate to the number of parameters in each model?
4.	What evidence is there that shrub and forest matter to gene flow from these analyses? Would you include them in a conclusion about landscape resistance in this system?
5.  What evidence is there that development influences gene flow from these analyses? Would you include it in a conclusion about landscape resistance in this system?


## 3. Your turn to test additional hypotheses!

Create your own (small) set of hypotheses to rank for evidence using the dataset provided. Modify the code above to complete the following steps: 

1.  Define your hypotheses.
2.  Calculate the VIF table for full model.
3.  Make a residual plot for full model.
4.  Create table of AICc and BIC weights.
5.  Create confidence intervals from models with high evidence weights.

What can you infer from your analysis about what influences gene flow of this species?

```{r message=FALSE, warning=TRUE, include=FALSE}
LandGenCourse::detachAllPackages()
```
